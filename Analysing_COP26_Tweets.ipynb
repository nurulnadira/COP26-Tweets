{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analysing COP26 Tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEclI/cXm8YXkExgbd30G5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurulnadira/COP26-Tweets/blob/main/Analysing_COP26_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this assignment, we put ourselves in the shoes of two data analysts working at the United Nation. Our task is to examine the impact of the conference on Twitter users and what attracted the attention of the users at the conference. \n",
        "\n",
        "We collected the tweets about COP26 conference to our list and tokenise the words to inspect them better. After cleaning the tokens, we looked at the frequency distribution of the tokens, drew a Word Cloud and plot the data. \n",
        "\n",
        "The words “world”, “energy”, “future” and “leader” are the most used words as most of the world leaders attended the conference and energy is the main topic that they focus on. The word \"patriarchy\", which is used to criticize the fact that almost all the leaders of the countries are male, is also among the most common words. The words “car” and “jets” were heavily used as many were criticising the irony of leaders flying jet instead of car to a climate change conference. Considering other commonly used words \"crisis\", \"lies\", it can be observed that the conference left a belated and disbelieving effect on people rather than a positive and comforting one. \n",
        "\n",
        "Since this code pulls new data every time it runs, the output of the code may change over time. We think that we have achieved a healthy result since we prepared this assignment at the conference time."
      ],
      "metadata": {
        "id": "39IvjSmZzN_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mp9l8nPaz1eu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEog-wCCzL7Q"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "\n",
        "!pip install tweepy\n",
        "import tweepy        # https://github.com/tweepy/tweepy\n",
        "import json\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import inaugural\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('inaugural')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add keys and secrets\n",
        "\n",
        "access_key = '****'\n",
        "access_secret = '****'\n",
        "api_key = '****'\n",
        "api_secret = '****'"
      ],
      "metadata": {
        "id": "Q_WtG75-zgnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
        "auth.set_access_token(access_key, access_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "v3Ds-AlJzliz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up list to hold tweets to append as we iterate through the pages\n",
        "\n",
        "cop26_tweets = []\n",
        "\n",
        "for page in tweepy.Cursor(api.search_tweets, \n",
        "                          q='COP26 OR cop26 OR COP OR COP-26 or #COP26 or #cop26', \n",
        "                          lang='en').pages(100):\n",
        "\n",
        "    cop26_tweets.append(page)"
      ],
      "metadata": {
        "id": "PSKZoPpwzoq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count tweets\n",
        "i=0\n",
        "for search_result in cop26_tweets:\n",
        "    for status in search_result: #for every tweet\n",
        "            i=i+1\n",
        "print(i)"
      ],
      "metadata": {
        "id": "j5k4bUY0zqBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of all tweets and exclude URLs\n",
        "\n",
        "def get_tweets(twitter_pages):\n",
        "    cop26_tweet_deets = []\n",
        "    for search_result in twitter_pages:\n",
        "        for status in search_result:\n",
        "            status.text=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', status.text) #remove URL\n",
        "            status.text=re.sub(\"@[A-Za-z0-9]+\",'',status.text)  #remove mention\n",
        "            if not status.text.startswith('RT @'):\n",
        "                cop26_tweet_deets.append(status.text) #Only take the status, exclude the account username\n",
        "    return cop26_tweet_deets"
      ],
      "metadata": {
        "id": "ieLSMwmizrl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweets(tokens):\n",
        "    \n",
        "    #Only take nouns\n",
        "    token_pos_tag = nltk.pos_tag(tokens)\n",
        "    token_nouns=[]\n",
        "    token_nouns=[word for (word,pos) in token_pos_tag if (pos=='NN' or pos=='NNS' or pos=='NNP' or pos=='NNPS')]\n",
        "    \n",
        "    #Convert token to lowercase\n",
        "    lowercase_tokens = [token.lower() for token in token_nouns]\n",
        "    \n",
        "    #Define additional words and collection words to be removed\n",
        "    additional_words=['@',':','rt','RT',',','https',\"'\",\"COP26\",\"cop26\",\"COP\",\"COP-26\",\"#COP26\",\"#cop26\",\"'\",\"’\"]\n",
        "    \n",
        "    #Define stopwords, punctuations, digits\n",
        "    remove_these = set(stopwords.words('english') + list(string.punctuation) + list(string.digits)+list(additional_words))\n",
        "    \n",
        "    #Remove additional words, stopwords, punctuations, digits\n",
        "    filtered_text = [token \n",
        "                 for token in lowercase_tokens \n",
        "                 if not token in remove_these]\n",
        "    \n",
        "    return filtered_text"
      ],
      "metadata": {
        "id": "zKyp8HEvztIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of all tweets\n",
        "cop26_tweet_deets=get_tweets(cop26_tweets) \n",
        "\n",
        "#Tokenize tweets\n",
        "tweets_string = \" \".join(cop26_tweet_deets)\n",
        "tokens = word_tokenize(tweets_string)\n",
        "\n",
        "#Clean tweets\n",
        "filtered_text=clean_tweets(tokens)\n",
        "\n",
        "#Calculate frequencies of tokens\n",
        "simple_frequencies_dict = Counter(filtered_text)"
      ],
      "metadata": {
        "id": "Z-c0HqSBzuoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_tweets_no_urls = pd.DataFrame(fdist.most_common(30),\n",
        "                             columns=['words', 'count'])\n",
        "\n",
        "clean_tweets_no_urls.head()"
      ],
      "metadata": {
        "id": "PqJr9cojzwMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Illustrate wordcloud\n",
        "from wordcloud import WordCloud\n",
        "cloud = WordCloud(width=800, height=260, max_font_size=160, \n",
        "                  colormap=\"viridis\", \n",
        "                  background_color='white',).generate_from_frequencies(simple_frequencies_dict)\n",
        "plt.figure(figsize=(16,12))\n",
        "plt.imshow(cloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qf8RNtU3zyM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequency Distribution\n",
        "fdist = FreqDist(simple_frequencies_dict)\n",
        "\n",
        "# Frequency Distribution Plot\n",
        "fdist.plot(30,cumulative=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MI3ynSg5z5oG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}